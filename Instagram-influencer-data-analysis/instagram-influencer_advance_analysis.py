# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HX0CLo7aiSrL29B1eb4a03Ceb1DYgqG1
"""

import pandas as pd

# Load the dataset
csv_path = '/content/top_insta_influencers_data.csv'  # Replace with your CSV file path
data = pd.read_csv(csv_path)

data.info()

def convert_to_numeric(value):
    if 'k' in value:
        return 1000 * float(value.replace('k', ''))
    elif 'm' in value:
        return 1000000 * float(value.replace('m', ''))
    elif 'b' in value:
        return 1000000000 * float(value.replace('b', ''))
    else:
        return float(value)

def convert_percentage_to_float(value):
    return float(value.strip('%')) / 100

data['posts'] = data['posts'].apply(convert_to_numeric)
data['followers'] = data['followers'].apply(convert_to_numeric)
data['avg_likes'] = data['avg_likes'].apply(convert_to_numeric)
data['new_post_avg_like'] = data['new_post_avg_like'].apply(convert_to_numeric)
data['total_likes'] = data['total_likes'].apply(convert_to_numeric)
data['60_day_eng_rate'] = data['60_day_eng_rate'].apply(convert_percentage_to_float)

data['country'] = data['country'].fillna('Unknown')

data.info()

import matplotlib.pyplot as plt
import seaborn as sns
# Display summary statistics
data.describe()

# Plotting histograms for numerical columns
num_cols = ['influence_score', 'posts', 'followers', 'avg_likes', '60_day_eng_rate', 'new_post_avg_like', 'total_likes']
data[num_cols].hist(bins=15, figsize=(15, 6), layout=(2, 4))

# Box plots for each numerical column
for col in num_cols:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x=data[col])
    plt.title(f'Box Plot of {col}')
    plt.show()

# Correlation matrix
corr_matrix = data[num_cols].corr()

# Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Pair plot for selected columns
sns.pairplot(data[num_cols])

# Average total_likes by country
plt.figure(figsize=(12, 6))
sns.barplot(x='total_likes', y='country', data=data, estimator=sum)
plt.title('Total Likes by Country')
plt.show()

fig, ax1 = plt.subplots(figsize=(20,10))
graph = sns.countplot(ax=ax1,x = 'country' , data = data)
graph.set_xticklabels(graph.get_xticklabels(),rotation=90)
for p in graph.patches:
    height = p.get_height()
    graph.text(p.get_x()+p.get_width()/2., height + 0.1,height ,ha="center")

from scipy import stats
# Example: Normality test for 'followers'
stat, p = stats.shapiro(data['followers'])
alpha = 0.05
if p > alpha:
    print('Sample looks Gaussian (fail to reject H0)')
else:
    print('Sample does not look Gaussian (reject H0)')

# Example: T-test between two countries
country1 = 'Country1'  # Replace with actual country name
country2 = 'Country2'  # Replace with actual country name

group1 = data[data['country'] == country1]['total_likes']
group2 = data[data['country'] == country2]['total_likes']

t_stat, p_val = stats.ttest_ind(group1, group2)
print(f'T-statistic: {t_stat}, P-value: {p_val}')

group1 = data[data['country'] == 'United States']['total_likes']
group2 = data[data['country'] == 'India']['total_likes']

t_stat, p_val = stats.ttest_ind(group1, group2, nan_policy='omit')  # Adding nan_policy='omit'
print(f'T-statistic: {t_stat}, P-value: {p_val}')

unique_countries = data['country'].unique()
print(unique_countries)

# Violin plot for total_likes in United States and India
plt.figure(figsize=(8, 6))
sns.violinplot(x='country', y='total_likes', data=data[data['country'].isin(['United States', 'India'])])
plt.title('Violin Plot of Total Likes for United States and India')
plt.show()

# Example: Chi-Square test for 'country' and 'influence_score'
contingency_table = pd.crosstab(data['country'], data['influence_score'])
chi2, p, dof, expected = stats.chi2_contingency(contingency_table)
print(f'Chi-square statistic: {chi2}, P-value: {p}')

# Correlation matrix
corr_matrix = data.corr()

# Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

# Define features and target
features = ['influence_score', 'posts', 'followers', 'new_post_avg_like']
X = data[features]
y = data['total_likes']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# Decision Tree Regressor
decision_tree_model = DecisionTreeRegressor(random_state=1)
decision_tree_model.fit(X_train, y_train)
dt_predictions = decision_tree_model.predict(X_test)
dt_mae = mean_absolute_error(y_test, dt_predictions)
print("Decision Tree MAE:", dt_mae)

# Random Forest Regressor
random_forest_model = RandomForestRegressor(random_state=1)
random_forest_model.fit(X_train, y_train)
rf_predictions = random_forest_model.predict(X_test)
rf_mae = mean_absolute_error(y_test, rf_predictions)
print("Random Forest MAE:", rf_mae)

# XGBoost Regressor
xgb_model = XGBRegressor(n_estimators=500, random_state=1)
xgb_model.fit(X_train, y_train)
xgb_predictions = xgb_model.predict(X_test)
xgb_mae = mean_absolute_error(y_test, xgb_predictions)
print("XGBoost MAE:", xgb_mae)

import matplotlib.pyplot as plt

feature_importance = xgb_model.feature_importances_
plt.barh(features, feature_importance)
plt.xlabel("XGBoost Feature Importance")
plt.show()