{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCdyR7rEgaUN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "chunk_size = 60000\n",
        "\n",
        "# Initialize an empty list to store the chunks\n",
        "processed_data_1 = []\n",
        "\n",
        "# Read the specified rows in chunks from the CSV file\n",
        "for chunk in pd.read_csv(r\"C:\\Users\\\", sep = '|', encoding = 'windows-1252',\n",
        "                         encoding_errors='ignore',on_bad_lines ='skip', chunksize = chunk_size):\n",
        "    print(\"added chunk\")\n",
        "    processed_data_1.append(chunk)\n",
        "\n",
        "# Concatenate the chunks into a single DataFrame\n",
        "processed_df_2 = pd.concat(processed_data_1)\n",
        "headers = pd.read_csv(r\"C:\\Users\\\", nrows = 1, sep = '|')\n",
        "processed_df_2.columns = headers.columns\n",
        "print('Processing data...')"
      ]
    }
  ]
}